{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4 MAGnet Modern Paintings Train",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhpham2601/Hashtag_GundGallery/blob/main/4_MAGnet_Modern_Paintings_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05ixUOhKBUAP",
        "outputId": "2168ec16-7836-4787-edec-1a69c6c6982d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8FyNk3MAYeA",
        "outputId": "093c22ee-5f06-43a0-db52-e12fb01f272e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ninja"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 19.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 23.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30 kB 12.8 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 51 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 61 kB 10.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 71 kB 9.8 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 81 kB 10.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 92 kB 11.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 102 kB 11.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 108 kB 11.5 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.2.3\n",
            "Cloning into 'stylegan2-pytorch'...\n",
            "remote: Not Found\n",
            "fatal: repository 'https://github.com/minhpham2601/Hashtag_GundGallery/stylegan2-pytorch/' not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/minhpham2601/Hashtag_GundGallery"
      ],
      "metadata": {
        "id": "lnmeeRTTAHP2",
        "outputId": "5ebca209-adb3-4aa2-d16d-234c71868875",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'Hashtag_GundGallery' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_LYN9rp1S_g",
        "outputId": "66446a52-7256-4dd7-e364-a2e74572ba4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/Hashtag_GundGallery/stylegan2-pytorch/prepare_data.py --out /content/drive/MyDrive/modern_art_processed_512/ --n_worker 8 --size 512 /content/drive/MyDrive/modern_art_resized_512/"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/content/Hashtag_GundGallery/stylegan2-pytorch/prepare_data.py\", line 24, in <module>\n",
            "    img, sizes=(128, 256, 512, 1024), resample=torchvision.transforms.InterpolationMode.LANCZOS, quality=100\n",
            "NameError: name 'torchvision' is not defined\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCgEg7SVWDv6"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/modern_results/\n",
        "!mkdir /content/drive/MyDrive/modern_results/sample\n",
        "!mkdir /content/drive/MyDrive/modern_results/checkpoint"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olfLlBkC6D1p",
        "outputId": "6e42fcb9-ef8f-4275-a9a3-ff2d2e90acbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/stylegan2-pytorch/train.py -h"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: train.py [-h] [--arch ARCH] [--iter ITER] [--batch BATCH]\n",
            "                [--n_sample N_SAMPLE] [--size SIZE] [--r1 R1]\n",
            "                [--path_regularize PATH_REGULARIZE]\n",
            "                [--path_batch_shrink PATH_BATCH_SHRINK]\n",
            "                [--d_reg_every D_REG_EVERY] [--g_reg_every G_REG_EVERY]\n",
            "                [--mixing MIXING] [--ckpt CKPT] [--lr LR]\n",
            "                [--channel_multiplier CHANNEL_MULTIPLIER] [--wandb]\n",
            "                [--local_rank LOCAL_RANK] [--augment] [--augment_p AUGMENT_P]\n",
            "                [--ada_target ADA_TARGET] [--ada_length ADA_LENGTH]\n",
            "                [--ada_every ADA_EVERY] [--data_dir DATA_DIR]\n",
            "                path\n",
            "\n",
            "StyleGAN2 trainer\n",
            "\n",
            "positional arguments:\n",
            "  path                  path to the lmdb dataset\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --arch ARCH           model architectures (stylegan2 | swagan)\n",
            "  --iter ITER           total training iterations\n",
            "  --batch BATCH         batch sizes for each gpus\n",
            "  --n_sample N_SAMPLE   number of the samples generated during training\n",
            "  --size SIZE           image sizes for the model\n",
            "  --r1 R1               weight of the r1 regularization\n",
            "  --path_regularize PATH_REGULARIZE\n",
            "                        weight of the path length regularization\n",
            "  --path_batch_shrink PATH_BATCH_SHRINK\n",
            "                        batch size reducing factor for the path length\n",
            "                        regularization (reduce memory consumption)\n",
            "  --d_reg_every D_REG_EVERY\n",
            "                        interval of the applying r1 regularization\n",
            "  --g_reg_every G_REG_EVERY\n",
            "                        interval of the applying path length regularization\n",
            "  --mixing MIXING       probability of latent code mixing\n",
            "  --ckpt CKPT           path to the checkpoints to resume training\n",
            "  --lr LR               learning rate\n",
            "  --channel_multiplier CHANNEL_MULTIPLIER\n",
            "                        channel multiplier factor for the model. config-f = 2,\n",
            "                        else = 1\n",
            "  --wandb               use weights and biases logging\n",
            "  --local_rank LOCAL_RANK\n",
            "                        local rank for distributed training\n",
            "  --augment             apply non leaking augmentation\n",
            "  --augment_p AUGMENT_P\n",
            "                        probability of applying augmentation. 0 = use adaptive\n",
            "                        augmentation\n",
            "  --ada_target ADA_TARGET\n",
            "                        target augmentation probability for adaptive\n",
            "                        augmentation\n",
            "  --ada_length ADA_LENGTH\n",
            "                        target duraing to reach augmentation probability for\n",
            "                        adaptive augmentation\n",
            "  --ada_every ADA_EVERY\n",
            "                        probability update interval of the adaptive\n",
            "                        augmentation\n",
            "  --data_dir DATA_DIR   Dataset root directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_Yo8lSBpC-",
        "outputId": "a59d0e43-6315-4ef8-d1b1-49efa12cba4d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/stylegan2-pytorch/train.py --data_dir /content/drive/MyDrive/modern_results --augment --arch swagan --size 512 /content/drive/MyDrive/modern_art_processed_512/ \\\n",
        "--ckpt /content/drive/MyDrive/modern_results_2/checkpoint/211000.pt"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load model: /content/drive/MyDrive/modern_results_2/checkpoint/211000.pt\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/stylegan2-pytorch/train.py\", line 487, in <module>\n",
            "    ckpt = torch.load(args.ckpt, map_location=lambda storage, loc: storage)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 594, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/modern_results_2/checkpoint/211000.pt'\n"
          ]
        }
      ]
    }
  ]
}