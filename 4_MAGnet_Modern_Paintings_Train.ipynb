{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4 MAGnet Modern Paintings Train",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhpham2601/Hashtag_GundGallery/blob/main/4_MAGnet_Modern_Paintings_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05ixUOhKBUAP",
        "outputId": "07fb2a4e-35e3-47fd-df49-51220601f2b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8FyNk3MAYeA",
        "outputId": "4fbe44e6-acd9-445a-e585-38893cf821ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ninja"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 14.3 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 11.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 51 kB 4.3 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 61 kB 5.1 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 71 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 81 kB 5.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 92 kB 6.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 108 kB 5.2 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/minhpham2601/Hashtag_GundGallery"
      ],
      "metadata": {
        "id": "lnmeeRTTAHP2",
        "outputId": "60912e46-7f7e-40e8-c998-962ad12e1141",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Hashtag_GundGallery'...\n",
            "remote: Enumerating objects: 212, done.\u001b[K\n",
            "remote: Counting objects: 100% (212/212), done.\u001b[K\n",
            "remote: Compressing objects: 100% (147/147), done.\u001b[K\n",
            "remote: Total 212 (delta 87), reused 171 (delta 57), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (212/212), 26.25 MiB | 26.41 MiB/s, done.\n",
            "Resolving deltas: 100% (87/87), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_LYN9rp1S_g",
        "outputId": "bd0f7b99-20c7-459c-a66a-f7dd37f86150",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/Hashtag_GundGallery/stylegan2-pytorch/prepare_data.py --out /content/drive/MyDrive/modern_art_processed_512/ --n_worker 8 --size 512 /content/drive/MyDrive/modern_art_resized_512/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Make dataset of image sizes: 512\n",
            "3041it [01:23, 36.22it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCgEg7SVWDv6"
      },
      "source": [
        "#Only run if you're running the the script the first time\n",
        "#!mkdir /content/drive/MyDrive/modern_results/\n",
        "#!mkdir /content/drive/MyDrive/modern_results/sample\n",
        "#!mkdir /content/drive/MyDrive/modern_results/checkpoint"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olfLlBkC6D1p",
        "outputId": "73d22ed0-7ff1-4063-912c-846944ef0197",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/Hashtag_GundGallery/stylegan2-pytorch/train.py -h"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: train.py [-h] [--arch ARCH] [--iter ITER] [--batch BATCH]\n",
            "                [--n_sample N_SAMPLE] [--size SIZE] [--r1 R1]\n",
            "                [--path_regularize PATH_REGULARIZE]\n",
            "                [--path_batch_shrink PATH_BATCH_SHRINK]\n",
            "                [--d_reg_every D_REG_EVERY] [--g_reg_every G_REG_EVERY]\n",
            "                [--mixing MIXING] [--ckpt CKPT] [--lr LR]\n",
            "                [--channel_multiplier CHANNEL_MULTIPLIER] [--wandb]\n",
            "                [--local_rank LOCAL_RANK] [--augment] [--augment_p AUGMENT_P]\n",
            "                [--ada_target ADA_TARGET] [--ada_length ADA_LENGTH]\n",
            "                [--ada_every ADA_EVERY] [--data_dir DATA_DIR]\n",
            "                path\n",
            "\n",
            "StyleGAN2 trainer\n",
            "\n",
            "positional arguments:\n",
            "  path                  path to the lmdb dataset\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --arch ARCH           model architectures (stylegan2 | swagan)\n",
            "  --iter ITER           total training iterations\n",
            "  --batch BATCH         batch sizes for each gpus\n",
            "  --n_sample N_SAMPLE   number of the samples generated during training\n",
            "  --size SIZE           image sizes for the model\n",
            "  --r1 R1               weight of the r1 regularization\n",
            "  --path_regularize PATH_REGULARIZE\n",
            "                        weight of the path length regularization\n",
            "  --path_batch_shrink PATH_BATCH_SHRINK\n",
            "                        batch size reducing factor for the path length\n",
            "                        regularization (reduce memory consumption)\n",
            "  --d_reg_every D_REG_EVERY\n",
            "                        interval of the applying r1 regularization\n",
            "  --g_reg_every G_REG_EVERY\n",
            "                        interval of the applying path length regularization\n",
            "  --mixing MIXING       probability of latent code mixing\n",
            "  --ckpt CKPT           path to the checkpoints to resume training\n",
            "  --lr LR               learning rate\n",
            "  --channel_multiplier CHANNEL_MULTIPLIER\n",
            "                        channel multiplier factor for the model. config-f = 2,\n",
            "                        else = 1\n",
            "  --wandb               use weights and biases logging\n",
            "  --local_rank LOCAL_RANK\n",
            "                        local rank for distributed training\n",
            "  --augment             apply non leaking augmentation\n",
            "  --augment_p AUGMENT_P\n",
            "                        probability of applying augmentation. 0 = use adaptive\n",
            "                        augmentation\n",
            "  --ada_target ADA_TARGET\n",
            "                        target augmentation probability for adaptive\n",
            "                        augmentation\n",
            "  --ada_length ADA_LENGTH\n",
            "                        target duraing to reach augmentation probability for\n",
            "                        adaptive augmentation\n",
            "  --ada_every ADA_EVERY\n",
            "                        probability update interval of the adaptive\n",
            "                        augmentation\n",
            "  --data_dir DATA_DIR   Dataset root directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_Yo8lSBpC-",
        "outputId": "e7243258-706c-417e-ad8c-76c1e75812f9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Delete the --ckpt part if you haven't run the file before\n",
        "#Change the check point datafile (002000.pt) to the most recent checkpoint\n",
        "!python /content/Hashtag_GundGallery/stylegan2-pytorch/train.py --data_dir /content/drive/MyDrive/modern_results --augment --arch swagan --size 512 /content/drive/MyDrive/modern_art_processed_512/ \\\n",
        "--ckpt /content/drive/MyDrive/modern_results/checkpoint/002000.pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load model: /content/drive/MyDrive/modern_results/checkpoint/002000.pt\n",
            "  0% 2000/800000 [00:00<?, ?it/s]/content/Hashtag_GundGallery/stylegan2-pytorch/op/conv2d_gradfix.py:89: UserWarning: conv2d_gradfix not supported on PyTorch 1.10.0+cu111. Falling back to torch.nn.functional.conv2d().\n",
            "  f\"conv2d_gradfix not supported on PyTorch {torch.__version__}. Falling back to torch.nn.functional.conv2d().\"\n",
            "d: 1.1780; g: 0.9391; r1: 0.0019; path: 0.0256; mean path: 0.0015; augment: 0.0000:   0% 2000/800000 [00:39<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n",
            "d: 1.2815; g: 0.4942; r1: 0.0028; path: 0.0463; mean path: 0.0149; augment: 0.0000:   0% 2034/800000 [11:23<4442:24:24, 20.04s/it]"
          ]
        }
      ]
    }
  ]
}