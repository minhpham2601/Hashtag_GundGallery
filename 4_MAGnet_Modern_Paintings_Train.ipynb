{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4 MAGnet Modern Paintings Train",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhpham2601/Hashtag_GundGallery/blob/main/4_MAGnet_Modern_Paintings_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05ixUOhKBUAP",
        "outputId": "03782802-8b33-4366-f115-e8808a8e2844",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8FyNk3MAYeA",
        "outputId": "2829b2c3-e444-477b-8314-695fb46d09a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ninja"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[?25l\r\u001b[K     |███                             | 10 kB 37.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 20 kB 19.8 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 30 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 40 kB 26.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 51 kB 15.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 61 kB 18.2 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 71 kB 20.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 81 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 92 kB 21.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 102 kB 23.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 108 kB 23.1 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/minhpham2601/Hashtag_GundGallery"
      ],
      "metadata": {
        "id": "lnmeeRTTAHP2",
        "outputId": "575a9c1e-c069-4285-ef44-5a6948e4e982",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Hashtag_GundGallery'...\n",
            "remote: Enumerating objects: 218, done.\u001b[K\n",
            "remote: Counting objects: 100% (218/218), done.\u001b[K\n",
            "remote: Compressing objects: 100% (153/153), done.\u001b[K\n",
            "remote: Total 218 (delta 90), reused 171 (delta 57), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (218/218), 26.26 MiB | 14.60 MiB/s, done.\n",
            "Resolving deltas: 100% (90/90), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_LYN9rp1S_g",
        "outputId": "406569f9-02e8-49ca-b330-f0500942d45d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/Hashtag_GundGallery/stylegan2-pytorch/prepare_data.py --out /content/drive/MyDrive/modern_art_processed_512/ --n_worker 8 --size 512 /content/drive/MyDrive/modern_art"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Make dataset of image sizes: 512\n",
            "25it [00:01, 12.56it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCgEg7SVWDv6"
      },
      "source": [
        "#Only run if you're running the the script the first time\n",
        "!mkdir /content/drive/MyDrive/modern_results/\n",
        "!mkdir /content/drive/MyDrive/modern_results/sample\n",
        "!mkdir /content/drive/MyDrive/modern_results/checkpoint"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olfLlBkC6D1p",
        "outputId": "73d22ed0-7ff1-4063-912c-846944ef0197",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/Hashtag_GundGallery/stylegan2-pytorch/train.py -h"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: train.py [-h] [--arch ARCH] [--iter ITER] [--batch BATCH]\n",
            "                [--n_sample N_SAMPLE] [--size SIZE] [--r1 R1]\n",
            "                [--path_regularize PATH_REGULARIZE]\n",
            "                [--path_batch_shrink PATH_BATCH_SHRINK]\n",
            "                [--d_reg_every D_REG_EVERY] [--g_reg_every G_REG_EVERY]\n",
            "                [--mixing MIXING] [--ckpt CKPT] [--lr LR]\n",
            "                [--channel_multiplier CHANNEL_MULTIPLIER] [--wandb]\n",
            "                [--local_rank LOCAL_RANK] [--augment] [--augment_p AUGMENT_P]\n",
            "                [--ada_target ADA_TARGET] [--ada_length ADA_LENGTH]\n",
            "                [--ada_every ADA_EVERY] [--data_dir DATA_DIR]\n",
            "                path\n",
            "\n",
            "StyleGAN2 trainer\n",
            "\n",
            "positional arguments:\n",
            "  path                  path to the lmdb dataset\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --arch ARCH           model architectures (stylegan2 | swagan)\n",
            "  --iter ITER           total training iterations\n",
            "  --batch BATCH         batch sizes for each gpus\n",
            "  --n_sample N_SAMPLE   number of the samples generated during training\n",
            "  --size SIZE           image sizes for the model\n",
            "  --r1 R1               weight of the r1 regularization\n",
            "  --path_regularize PATH_REGULARIZE\n",
            "                        weight of the path length regularization\n",
            "  --path_batch_shrink PATH_BATCH_SHRINK\n",
            "                        batch size reducing factor for the path length\n",
            "                        regularization (reduce memory consumption)\n",
            "  --d_reg_every D_REG_EVERY\n",
            "                        interval of the applying r1 regularization\n",
            "  --g_reg_every G_REG_EVERY\n",
            "                        interval of the applying path length regularization\n",
            "  --mixing MIXING       probability of latent code mixing\n",
            "  --ckpt CKPT           path to the checkpoints to resume training\n",
            "  --lr LR               learning rate\n",
            "  --channel_multiplier CHANNEL_MULTIPLIER\n",
            "                        channel multiplier factor for the model. config-f = 2,\n",
            "                        else = 1\n",
            "  --wandb               use weights and biases logging\n",
            "  --local_rank LOCAL_RANK\n",
            "                        local rank for distributed training\n",
            "  --augment             apply non leaking augmentation\n",
            "  --augment_p AUGMENT_P\n",
            "                        probability of applying augmentation. 0 = use adaptive\n",
            "                        augmentation\n",
            "  --ada_target ADA_TARGET\n",
            "                        target augmentation probability for adaptive\n",
            "                        augmentation\n",
            "  --ada_length ADA_LENGTH\n",
            "                        target duraing to reach augmentation probability for\n",
            "                        adaptive augmentation\n",
            "  --ada_every ADA_EVERY\n",
            "                        probability update interval of the adaptive\n",
            "                        augmentation\n",
            "  --data_dir DATA_DIR   Dataset root directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_Yo8lSBpC-",
        "outputId": "8afe57d1-ee49-419d-f50b-1ed03a19cab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Delete the --ckpt part if you haven't run the file before\n",
        "#Change the check point datafile (002000.pt) to the most recent checkpoint\n",
        "!python /content/Hashtag_GundGallery/stylegan2-pytorch/train.py --data_dir /content/drive/MyDrive/modern_results --augment --arch swagan --size 512 /content/drive/MyDrive/modern_art_processed_512/ \\\n",
        "--ckpt /content/drive/MyDrive/modern_results/checkpoint/008000.pt"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load model: /content/drive/MyDrive/modern_results/checkpoint/008000.pt\n",
            "  1% 8000/800000 [00:00<?, ?it/s]/content/Hashtag_GundGallery/stylegan2-pytorch/op/conv2d_gradfix.py:89: UserWarning: conv2d_gradfix not supported on PyTorch 1.10.0+cu111. Falling back to torch.nn.functional.conv2d().\n",
            "  f\"conv2d_gradfix not supported on PyTorch {torch.__version__}. Falling back to torch.nn.functional.conv2d().\"\n",
            "d: 0.8611; g: 1.2816; r1: 0.0059; path: 0.0473; mean path: 0.0021; augment: 0.0000:   1% 8000/800000 [00:14<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torchvision/utils.py:50: UserWarning: range will be deprecated, please use value_range instead.\n",
            "  warnings.warn(warning)\n",
            "d: 0.5733; g: 1.6004; r1: 0.0217; path: 0.0044; mean path: 0.1112; augment: 0.0000:   1% 8317/800000 [27:22<1136:06:50,  5.17s/it]"
          ]
        }
      ]
    }
  ]
}