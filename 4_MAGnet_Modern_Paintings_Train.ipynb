{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4 MAGnet Modern Paintings Train",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhpham2601/Hashtag_GundGallery/blob/main/4_MAGnet_Modern_Paintings_Train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05ixUOhKBUAP",
        "outputId": "5273a168-d82e-421d-f7f2-c2a6b11470a6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8FyNk3MAYeA",
        "outputId": "6f79bb07-a0bf-49e0-bd0e-ee1dae94a52f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ninja"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ninja\n",
            "  Downloading ninja-1.10.2.3-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.whl (108 kB)\n",
            "\u001b[K     |████████████████████████████████| 108 kB 5.3 MB/s \n",
            "\u001b[?25hInstalling collected packages: ninja\n",
            "Successfully installed ninja-1.10.2.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/minhpham2601/Hashtag_GundGallery"
      ],
      "metadata": {
        "id": "lnmeeRTTAHP2",
        "outputId": "a8fadac7-8abf-4d60-908b-0f03c4884401",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Hashtag_GundGallery'...\n",
            "remote: Enumerating objects: 209, done.\u001b[K\n",
            "remote: Counting objects: 100% (209/209), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 209 (delta 85), reused 171 (delta 57), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (209/209), 26.25 MiB | 31.62 MiB/s, done.\n",
            "Resolving deltas: 100% (85/85), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_LYN9rp1S_g",
        "outputId": "b77613d1-1200-4d41-b4d8-0728a3653d0a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/Hashtag_GundGallery/stylegan2-pytorch/prepare_data.py --out /content/drive/MyDrive/modern_art_processed_512/ --n_worker 8 --size 512 /content/drive/MyDrive/modern_art_resized_512/"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Make dataset of image sizes: 512\n",
            "3042it [01:31, 33.29it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCgEg7SVWDv6"
      },
      "source": [
        "!mkdir /content/drive/MyDrive/modern_results/\n",
        "!mkdir /content/drive/MyDrive/modern_results/sample\n",
        "!mkdir /content/drive/MyDrive/modern_results/checkpoint"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olfLlBkC6D1p",
        "outputId": "73d22ed0-7ff1-4063-912c-846944ef0197",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/Hashtag_GundGallery/stylegan2-pytorch/train.py -h"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: train.py [-h] [--arch ARCH] [--iter ITER] [--batch BATCH]\n",
            "                [--n_sample N_SAMPLE] [--size SIZE] [--r1 R1]\n",
            "                [--path_regularize PATH_REGULARIZE]\n",
            "                [--path_batch_shrink PATH_BATCH_SHRINK]\n",
            "                [--d_reg_every D_REG_EVERY] [--g_reg_every G_REG_EVERY]\n",
            "                [--mixing MIXING] [--ckpt CKPT] [--lr LR]\n",
            "                [--channel_multiplier CHANNEL_MULTIPLIER] [--wandb]\n",
            "                [--local_rank LOCAL_RANK] [--augment] [--augment_p AUGMENT_P]\n",
            "                [--ada_target ADA_TARGET] [--ada_length ADA_LENGTH]\n",
            "                [--ada_every ADA_EVERY] [--data_dir DATA_DIR]\n",
            "                path\n",
            "\n",
            "StyleGAN2 trainer\n",
            "\n",
            "positional arguments:\n",
            "  path                  path to the lmdb dataset\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  --arch ARCH           model architectures (stylegan2 | swagan)\n",
            "  --iter ITER           total training iterations\n",
            "  --batch BATCH         batch sizes for each gpus\n",
            "  --n_sample N_SAMPLE   number of the samples generated during training\n",
            "  --size SIZE           image sizes for the model\n",
            "  --r1 R1               weight of the r1 regularization\n",
            "  --path_regularize PATH_REGULARIZE\n",
            "                        weight of the path length regularization\n",
            "  --path_batch_shrink PATH_BATCH_SHRINK\n",
            "                        batch size reducing factor for the path length\n",
            "                        regularization (reduce memory consumption)\n",
            "  --d_reg_every D_REG_EVERY\n",
            "                        interval of the applying r1 regularization\n",
            "  --g_reg_every G_REG_EVERY\n",
            "                        interval of the applying path length regularization\n",
            "  --mixing MIXING       probability of latent code mixing\n",
            "  --ckpt CKPT           path to the checkpoints to resume training\n",
            "  --lr LR               learning rate\n",
            "  --channel_multiplier CHANNEL_MULTIPLIER\n",
            "                        channel multiplier factor for the model. config-f = 2,\n",
            "                        else = 1\n",
            "  --wandb               use weights and biases logging\n",
            "  --local_rank LOCAL_RANK\n",
            "                        local rank for distributed training\n",
            "  --augment             apply non leaking augmentation\n",
            "  --augment_p AUGMENT_P\n",
            "                        probability of applying augmentation. 0 = use adaptive\n",
            "                        augmentation\n",
            "  --ada_target ADA_TARGET\n",
            "                        target augmentation probability for adaptive\n",
            "                        augmentation\n",
            "  --ada_length ADA_LENGTH\n",
            "                        target duraing to reach augmentation probability for\n",
            "                        adaptive augmentation\n",
            "  --ada_every ADA_EVERY\n",
            "                        probability update interval of the adaptive\n",
            "                        augmentation\n",
            "  --data_dir DATA_DIR   Dataset root directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kj_Yo8lSBpC-",
        "outputId": "64ac05ac-a9c2-4f52-bc72-39f1fa481c4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!python /content/Hashtag_GundGallery/stylegan2-pytorch/train.py --data_dir /content/drive/MyDrive/modern_results --augment --arch swagan --size 512 /content/drive/MyDrive/modern_art_processed_512/ \\\n",
        "--ckpt /content/drive/MyDrive/modern_results_2/checkpoint/211000.pt"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load model: /content/drive/MyDrive/modern_results_2/checkpoint/211000.pt\n",
            "Traceback (most recent call last):\n",
            "  File \"/content/Hashtag_GundGallery/stylegan2-pytorch/train.py\", line 487, in <module>\n",
            "    ckpt = torch.load(args.ckpt, map_location=lambda storage, loc: storage)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 594, in load\n",
            "    with _open_file_like(f, 'rb') as opened_file:\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 230, in _open_file_like\n",
            "    return _open_file(name_or_buffer, mode)\n",
            "  File \"/usr/local/lib/python3.7/dist-packages/torch/serialization.py\", line 211, in __init__\n",
            "    super(_open_file, self).__init__(open(name, mode))\n",
            "FileNotFoundError: [Errno 2] No such file or directory: '/content/drive/MyDrive/modern_results_2/checkpoint/211000.pt'\n"
          ]
        }
      ]
    }
  ]
}