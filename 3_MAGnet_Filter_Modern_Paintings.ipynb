{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "3 Filter Modern Paintings",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/minhpham2601/Hashtag_GundGallery/blob/main/3_MAGnet_Filter_Modern_Paintings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kx9aJ86ODr_",
        "outputId": "613263ac-9e6a-45be-80cf-beca77bbdc03",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_9ub-yFB8TE",
        "outputId": "1be2aabc-d9e8-424c-f5d2-00b4db3eea40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Sort through the file names in a folder alphabettically:\n",
        "import glob\n",
        "image_files = sorted(glob.glob(\"/content/drive/MyDrive/modern_art_resized_512/paintings/*.jpg\")) \n",
        "#Return a possibly-empty list of path names that match pathname, which must be a string containing a path specification.\n",
        "print(len(image_files))\n",
        "#Total how many processed images we have in our database (original number of the images*3)\n",
        "print(image_files[:4])\n",
        "#Check the first 4 images: processed images are sorted by _bot, _ctr, _top"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3042\n",
            "['/content/drive/MyDrive/modern_art_resized_512/paintings/alexei-harlamoff_a-fair-rose_bot.jpg', '/content/drive/MyDrive/modern_art_resized_512/paintings/alexei-harlamoff_a-fair-rose_ctr.jpg', '/content/drive/MyDrive/modern_art_resized_512/paintings/alexei-harlamoff_a-fair-rose_top.jpg', '/content/drive/MyDrive/modern_art_resized_512/paintings/alexei-harlamoff_a-neapolitan-girl_bot.jpg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C1hkDT38hSaP",
        "outputId": "0191e287-f0f4-42e4-8a34-c3e54ba7b4f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "print(\"Torch version:\", torch.__version__)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Torch version: 1.10.0+cu111\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cboKZocQlSYX",
        "outputId": "0336232a-83fd-4c9c-edd1-18b4b48b4326",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "#Download the model database file of CLIP:\n",
        "!wget https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt -O model.pt"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-31 12:54:24--  https://openaipublic.azureedge.net/clip/models/40d365715913c9da98579312b702a82c18be219cc2a73407c4526f58eba950af/ViT-B-32.pt\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.219.38, 13.107.227.38, 2620:1ec:bdf::38, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.219.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 353976522 (338M) [application/octet-stream]\n",
            "Saving to: ‘model.pt’\n",
            "\n",
            "model.pt            100%[===================>] 337.58M  86.4MB/s    in 4.2s    \n",
            "\n",
            "2022-03-31 12:54:28 (80.7 MB/s) - ‘model.pt’ saved [353976522/353976522]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IBRVTY9lbGm8",
        "outputId": "c42d3c6f-cd6f-4ad5-861f-cde9c216a1ab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "model = torch.jit.load(\"model.pt\").cuda().eval()\n",
        "  #.cuda():moves all parameters and buffer of a of torch.jit._script.RecursiveScriptModule instance to the GPU.\n",
        "    #.eval(): set the module to evaluation mode.\n",
        "input_resolution = model.input_resolution.item()\n",
        "  #.input_resolution: a parameter of a pt database that is assigned as a item to a variable.\n",
        "context_length = model.context_length.item()\n",
        "vocab_size = model.vocab_size.item()\n",
        "\n",
        "print(\"Model parameters:\", f\"{np.sum([int(np.prod(p.shape)) for p in model.parameters()]):,}\")\n",
        "print(\"Input resolution:\", input_resolution)\n",
        "print(\"Context length:\", context_length)\n",
        "print(\"Vocab size:\", vocab_size)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model parameters: 151,277,313\n",
            "Input resolution: 224\n",
            "Context length: 77\n",
            "Vocab size: 49408\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "help(model.parameters())"
      ],
      "metadata": {
        "id": "etF5XLOeEj7e",
        "outputId": "51a978a2-8d82-45e2-8f9a-4face828edaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on generator object:\n",
            "\n",
            "parameters = class generator(object)\n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __del__(...)\n",
            " |  \n",
            " |  __getattribute__(self, name, /)\n",
            " |      Return getattr(self, name).\n",
            " |  \n",
            " |  __iter__(self, /)\n",
            " |      Implement iter(self).\n",
            " |  \n",
            " |  __next__(self, /)\n",
            " |      Implement next(self).\n",
            " |  \n",
            " |  __repr__(self, /)\n",
            " |      Return repr(self).\n",
            " |  \n",
            " |  close(...)\n",
            " |      close() -> raise GeneratorExit inside generator.\n",
            " |  \n",
            " |  send(...)\n",
            " |      send(arg) -> send 'arg' into generator,\n",
            " |      return next yielded value or raise StopIteration.\n",
            " |  \n",
            " |  throw(...)\n",
            " |      throw(typ[,val[,tb]]) -> raise exception in generator,\n",
            " |      return next yielded value or raise StopIteration.\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors defined here:\n",
            " |  \n",
            " |  gi_code\n",
            " |  \n",
            " |  gi_frame\n",
            " |  \n",
            " |  gi_running\n",
            " |  \n",
            " |  gi_yieldfrom\n",
            " |      object being iterated by yield from, or None\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6cpiIFHp9N6"
      },
      "source": [
        "import torchvision.transforms\n",
        "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
        "from PIL import Image\n",
        "\n",
        "preprocess = Compose([\n",
        "    Resize(input_resolution, interpolation=torchvision.transforms.InterpolationMode.BICUBIC),\n",
        "    ToTensor()\n",
        "])\n",
        "\n",
        "image_mean = torch.tensor([0.48145466, 0.4578275, 0.40821073]).cuda()\n",
        "image_std = torch.tensor([0.26862954, 0.26130258, 0.27577711]).cuda()"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGom156-i2kL",
        "outputId": "c54524cc-3509-4c6e-cd96-53904fb9088c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz -O bpe_simple_vocab_16e6.txt.gz"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-03-31 13:07:33--  https://openaipublic.azureedge.net/clip/bpe_simple_vocab_16e6.txt.gz\n",
            "Resolving openaipublic.azureedge.net (openaipublic.azureedge.net)... 13.107.246.38, 13.107.213.38, 2620:1ec:bdf::38, ...\n",
            "Connecting to openaipublic.azureedge.net (openaipublic.azureedge.net)|13.107.246.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1356917 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘bpe_simple_vocab_16e6.txt.gz’\n",
            "\n",
            "\r          bpe_simpl   0%[                    ]       0  --.-KB/s               \rbpe_simple_vocab_16 100%[===================>]   1.29M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-03-31 13:07:33 (12.4 MB/s) - ‘bpe_simple_vocab_16e6.txt.gz’ saved [1356917/1356917]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pCKcGHcGUnRa",
        "outputId": "a913549b-c3e6-4438-a9fb-fee7400d6b5d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ftfy"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ftfy\n",
            "  Downloading ftfy-6.1.1-py3-none-any.whl (53 kB)\n",
            "\u001b[?25l\r\u001b[K     |██████▏                         | 10 kB 20.0 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 20 kB 11.1 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 30 kB 9.1 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 40 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 51 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 53 kB 1.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: wcwidth>=0.2.5 in /usr/local/lib/python3.7/dist-packages (from ftfy) (0.2.5)\n",
            "Installing collected packages: ftfy\n",
            "Successfully installed ftfy-6.1.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "toGtcd-Ji_MD"
      },
      "source": [
        "import os\n",
        "from functools import lru_cache\n",
        "import ftfy\n",
        "import regex as re\n",
        "\n",
        "@lru_cache()\n",
        "def bytes_to_unicode():\n",
        "    \"\"\"\n",
        "    Returns list of utf-8 byte and a corresponding list of unicode strings.\n",
        "    The reversible bpe codes work on unicode strings.\n",
        "    This means you need a large # of unicode characters in your vocab if you want to avoid UNKs.\n",
        "    When you're at something like a 10B token dataset you end up needing around 5K for decent coverage.\n",
        "    This is a signficant percentage of your normal, say, 32K bpe vocab.\n",
        "    To avoid that, we want lookup tables between utf-8 bytes and unicode strings.\n",
        "    And avoids mapping to whitespace/control characters the bpe code barfs on.\n",
        "    \"\"\"\n",
        "    bs = list(range(ord(\"!\"), ord(\"~\")+1))+list(range(ord(\"¡\"), ord(\"¬\")+1))+list(range(ord(\"®\"), ord(\"ÿ\")+1))\n",
        "    cs = bs[:]\n",
        "    n = 0\n",
        "    for b in range(2**8):\n",
        "        if b not in bs:\n",
        "            bs.append(b)\n",
        "            cs.append(2**8+n)\n",
        "            n += 1\n",
        "    cs = [chr(n) for n in cs]\n",
        "    return dict(zip(bs, cs))\n",
        "\n",
        "\n",
        "def get_pairs(word):\n",
        "    \"\"\"Return set of symbol pairs in a word.\n",
        "    Word is represented as tuple of symbols (symbols being variable-length strings).\n",
        "    \"\"\"\n",
        "    pairs = set()\n",
        "    prev_char = word[0]\n",
        "    for char in word[1:]:\n",
        "        pairs.add((prev_char, char))\n",
        "        prev_char = char\n",
        "    return pairs\n",
        "\n",
        "def basic_clean(text):\n",
        "    text = ftfy.fix_text(text)\n",
        "    text = html.unescape(html.unescape(text))\n",
        "    return text.strip()\n",
        "\n",
        "def whitespace_clean(text):\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "class SimpleTokenizer(object):\n",
        "    def __init__(self, bpe_path: str = \"bpe_simple_vocab_16e6.txt.gz\"):\n",
        "        self.byte_encoder = bytes_to_unicode()\n",
        "        self.byte_decoder = {v: k for k, v in self.byte_encoder.items()}\n",
        "        merges = gzip.open(bpe_path).read().decode(\"utf-8\").split('\\n')\n",
        "        merges = merges[1:49152-256-2+1]\n",
        "        merges = [tuple(merge.split()) for merge in merges]\n",
        "        vocab = list(bytes_to_unicode().values())\n",
        "        vocab = vocab + [v+'</w>' for v in vocab]\n",
        "        for merge in merges:\n",
        "            vocab.append(''.join(merge))\n",
        "        vocab.extend(['<|startoftext|>', '<|endoftext|>'])\n",
        "        self.encoder = dict(zip(vocab, range(len(vocab))))\n",
        "        self.decoder = {v: k for k, v in self.encoder.items()}\n",
        "        self.bpe_ranks = dict(zip(merges, range(len(merges))))\n",
        "        self.cache = {'<|startoftext|>': '<|startoftext|>', '<|endoftext|>': '<|endoftext|>'}\n",
        "        self.pat = re.compile(r\"\"\"<\\|startoftext\\|>|<\\|endoftext\\|>|'s|'t|'re|'ve|'m|'ll|'d|[\\p{L}]+|[\\p{N}]|[^\\s\\p{L}\\p{N}]+\"\"\", re.IGNORECASE)\n",
        "\n",
        "    def bpe(self, token):\n",
        "        if token in self.cache:\n",
        "            return self.cache[token]\n",
        "        word = tuple(token[:-1]) + ( token[-1] + '</w>',)\n",
        "        pairs = get_pairs(word)\n",
        "\n",
        "        if not pairs:\n",
        "            return token+'</w>'\n",
        "\n",
        "        while True:\n",
        "            bigram = min(pairs, key = lambda pair: self.bpe_ranks.get(pair, float('inf')))\n",
        "            if bigram not in self.bpe_ranks:\n",
        "                break\n",
        "            first, second = bigram\n",
        "            new_word = []\n",
        "            i = 0\n",
        "            while i < len(word):\n",
        "                try:\n",
        "                    j = word.index(first, i)\n",
        "                    new_word.extend(word[i:j])\n",
        "                    i = j\n",
        "                except:\n",
        "                    new_word.extend(word[i:])\n",
        "                    break\n",
        "\n",
        "                if word[i] == first and i < len(word)-1 and word[i+1] == second:\n",
        "                    new_word.append(first+second)\n",
        "                    i += 2\n",
        "                else:\n",
        "                    new_word.append(word[i])\n",
        "                    i += 1\n",
        "            new_word = tuple(new_word)\n",
        "            word = new_word\n",
        "            if len(word) == 1:\n",
        "                break\n",
        "            else:\n",
        "                pairs = get_pairs(word)\n",
        "        word = ' '.join(word)\n",
        "        self.cache[token] = word\n",
        "        return word\n",
        "\n",
        "    def encode(self, text):\n",
        "        bpe_tokens = []\n",
        "        text = whitespace_clean(basic_clean(text)).lower()\n",
        "        for token in re.findall(self.pat, text):\n",
        "            token = ''.join(self.byte_encoder[b] for b in token.encode('utf-8'))\n",
        "            bpe_tokens.extend(self.encoder[bpe_token] for bpe_token in self.bpe(token).split(' '))\n",
        "        return bpe_tokens\n",
        "\n",
        "    def decode(self, tokens):\n",
        "        text = ''.join([self.decoder[token] for token in tokens])\n",
        "        text = bytearray([self.byte_decoder[c] for c in text]).decode('utf-8', errors=\"replace\").replace('</w>', ' ')\n",
        "        return text"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EElyF423O8qT",
        "outputId": "6946e0ca-80ea-477e-e1e8-1474789d4af5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ipyplot"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipyplot\n",
            "  Downloading ipyplot-1.1.1-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from ipyplot) (1.21.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from ipyplot) (7.1.2)\n",
            "Requirement already satisfied: IPython in /usr/local/lib/python3.7/dist-packages (from ipyplot) (5.5.0)\n",
            "Collecting shortuuid\n",
            "  Downloading shortuuid-1.0.8-py3-none-any.whl (9.5 kB)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from IPython->ipyplot) (5.1.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from IPython->ipyplot) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from IPython->ipyplot) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from IPython->ipyplot) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from IPython->ipyplot) (4.8.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from IPython->ipyplot) (4.4.2)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from IPython->ipyplot) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from IPython->ipyplot) (57.4.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->ipyplot) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->IPython->ipyplot) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->IPython->ipyplot) (0.7.0)\n",
            "Installing collected packages: shortuuid, ipyplot\n",
            "Successfully installed ipyplot-1.1.1 shortuuid-1.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncSKms93VOdZ",
        "outputId": "5b8f30db-271d-4d56-a5ed-ecd0399a4902",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import random\n",
        "import array\n",
        "all_images = []\n",
        "all_file_names = []\n",
        "\n",
        "for i, f in enumerate(image_files):\n",
        "  try:\n",
        "    image = Image.open(f)\n",
        "    all_images.append(image)\n",
        "    all_file_names.append(f)\n",
        "  except:\n",
        "    print(\"error reading\", f)\n",
        "\n",
        "  if i%100 == 0:\n",
        "    print(i)\n",
        "\n",
        "print (\"Total no of images retrived: \", len(all_images))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "100\n",
            "200\n",
            "300\n",
            "400\n",
            "500\n",
            "600\n",
            "700\n",
            "800\n",
            "900\n",
            "1000\n",
            "1100\n",
            "1200\n",
            "1300\n",
            "1400\n",
            "1500\n",
            "1600\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lwb1dCRYZeHI"
      },
      "source": [
        "import ipyplot\n",
        "ipyplot.plot_images(all_images, max_images=44, img_width=150)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvO9vC33pZdI"
      },
      "source": [
        "image_features = torch.empty((0, 512))\n",
        "step = 1000\n",
        "\n",
        "for start in range(0, len(all_images), step):\n",
        "  end = min(start + step, len(all_images))\n",
        "  print(start, end)\n",
        "  images = [preprocess(im) for im in all_images[start:end]]\n",
        "  image_input = torch.tensor(np.stack(images)).cuda()\n",
        "  image_input -= image_mean[:, None, None]\n",
        "  image_input /= image_std[:, None, None]\n",
        "  with torch.no_grad():\n",
        "    image_feature_batch = model.encode_image(image_input).float()\n",
        "  image_features = torch.cat([image_features, image_feature_batch.cpu()], dim=0)\n",
        "  \n",
        "image_features /= image_features.norm(dim=-1, keepdim=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-OOTtgVanHP"
      },
      "source": [
        "import gzip\n",
        "tokenizer = SimpleTokenizer()\n",
        "\n",
        "def get_text_features(sentence):\n",
        "  text_tokens = [tokenizer.encode(\"%s \"%(sentence) + \"<|endoftext|>\")]\n",
        "  text_input = torch.zeros(len(text_tokens), model.context_length, dtype=torch.long)\n",
        "  for i, tokens in enumerate(text_tokens):\n",
        "    text_input[i, :len(tokens)] = torch.tensor(tokens)\n",
        "    \n",
        "  text_input = text_input.cuda()\n",
        "  with torch.no_grad():\n",
        "    text_features = model.encode_text(text_input).float()\n",
        "    text_features /= text_features.norm(dim=-1, keepdim=True)\n",
        "\n",
        "  return text_features\n",
        "\n",
        "def get_top_N_semantic_similarity(similarity_list, N, reverse):\n",
        "  results = zip(range(len(similarity_list)), similarity_list)\n",
        "  results = sorted(results, key=lambda x: x[1], reverse=reverse)\n",
        "  top_N_images = []\n",
        "  scores = []\n",
        "  indices = []\n",
        "  for index,score in results[:N]:\n",
        "    scores.append(score)\n",
        "    top_N_images.append(all_images[index])\n",
        "    indices.append(index)\n",
        "  return scores, top_N_images, indices"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arM9-OcpbCYz"
      },
      "source": [
        "import html\n",
        "semantic_search_phrase = \"modern painting\"\n",
        "text_features_extracted = get_text_features(semantic_search_phrase)\n",
        "similarity = text_features_extracted.cpu().numpy() @ image_features.cpu().numpy().T\n",
        "\n",
        "similarity = similarity[0]\n",
        "scores, imgs, indices = get_top_N_semantic_similarity(similarity, 28, True)\n",
        "print(\"scores \", scores)\n",
        "result_labels = []\n",
        "ipyplot.plot_images(imgs, img_width=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sulUS5-0aKrL"
      },
      "source": [
        "scores, imgs, indices = get_top_N_semantic_similarity(similarity, 28, False)\n",
        "print(\"scores \", scores)\n",
        "ipyplot.plot_images(imgs, img_width=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZR9xChjE6XmY"
      },
      "source": [
        "cutoff = 10000\n",
        "scores, imgs, indices = get_top_N_semantic_similarity(similarity, cutoff, True)\n",
        "print(\"scores \", scores)\n",
        "ipyplot.plot_images(imgs[cutoff-28:cutoff], img_width=200)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vNw5PxHQ4Hgu"
      },
      "source": [
        "num_to_cut = len(image_files) - cutoff\n",
        "print(num_to_cut)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XyKADYsx49ni"
      },
      "source": [
        "import shutil\n",
        "\n",
        "scores, imgs, indices = get_top_N_semantic_similarity(similarity, num_to_cut, False)\n",
        "for index in indices:\n",
        "  src_file = image_files[index]\n",
        "  dst_file = src_file.replace(\"modern_art_resized_512/paintings\", \"modern_salon_des_refuses\")\n",
        "  print(src_file, dst_file)\n",
        "  shutil.move(src_file, dst_file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}